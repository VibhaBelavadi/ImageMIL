{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "from linear_classifier import LinearClassifier\n",
    "from sil import SIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#haven't changed this yet\n",
    "class ResultsReport:\n",
    "    def __init__(self,label_names=None):\n",
    "        self.res = {}\n",
    "        self.label_names = label_names\n",
    "    def add(self,metric,result):\n",
    "        if metric not in self.res:\n",
    "            self.res[metric] = []\n",
    "        self.res[metric].append( result )\n",
    "    def print_summary(self,metric=None):\n",
    "        if metric is None:\n",
    "            for metric in sorted(self.res.keys()):\n",
    "                if metric != 'confusion':\n",
    "                    self.print_summary(metric)\n",
    "            self.print_summary('confusion')\n",
    "            return\n",
    "        if metric != 'confusion':\n",
    "            mean = np.mean(self.res[metric])\n",
    "            std = np.std(self.res[metric])\n",
    "            ste = std/np.sqrt(len(self.res[metric])-1)\n",
    "            print('%s %f %f %f' % (metric,mean,std,ste) )\n",
    "        else:\n",
    "            print('confusion')\n",
    "            print(('%s '*len(self.label_names))%tuple(self.label_names))\n",
    "            print(sum(self.res['confusion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser( description='Compute CNN features.' )\n",
    "    parser.add_argument('--out_dir', '-o', required=True, help='output directory' )\n",
    "    parser.add_argument('--model', '-m', required=True, help='CNN model' )\n",
    "    parser.add_argument('--layer', '-l', required=True, help='CNN layer' )\n",
    "    parser.add_argument('--instance-size', help='instance size' )\n",
    "    parser.add_argument('--instance-stride', help='instance stride' )\n",
    "    parser.add_argument('--pool-size', '-p', help='mean pooling size' )\n",
    "    parser.add_argument('--cat', help='label categories to train (comma separated); default: all' )\n",
    "    parser.add_argument('--calibrate', action='store_true', help='calibrate classifier' )\n",
    "    parser.add_argument('--metric', help='metric to optimize during parameter search (accuracy, balanced_accuracy, roc_auc); default: accuracy' )\n",
    "    parser.add_argument('--classifier', '-c', help='classifier (svm or logistic); default: all' )\n",
    "    parser.add_argument('--kernel', help='SVM kernel; default: linear' )\n",
    "    parser.add_argument('--mi', help='MI type (none, median, quantile); default: none (compute mean across images)' )\n",
    "    parser.add_argument('--quantiles', '-q', help='Number of quantiles; default: 16' )\n",
    "    parser.add_argument('--sample-weight', help='Weight samples by classification category and this one' )\n",
    "    parser.add_argument('--group', help='Class groups for reporting results' )\n",
    "    parser.add_argument('--cv-fold-files', help='cross-validation fold files' )\n",
    "    parser.add_argument('--cv-folds', help='cross-validation folds' )\n",
    "    parser.add_argument('--cv-lno', help='cross-validation leave n out' )\n",
    "    parser.add_argument('--n-jobs', help='number of parallel threads' )\n",
    "    args = parser.parse_args()\n",
    "    out_dir = args.out_dir\n",
    "    if len(out_dir) > 1 and out_dir[-1] != '/':\n",
    "        out_dir += '/'\n",
    "    model_name = args.model\n",
    "    layer = args.layer\n",
    "    instance_size = args.instance_size\n",
    "    instance_stride = args.instance_stride\n",
    "    pool_size = args.pool_size\n",
    "    categories = args.cat\n",
    "    metric = args.metric\n",
    "    calibrate = args.calibrate\n",
    "    classifier = args.classifier\n",
    "    kernel = args.kernel\n",
    "    mi_type = args.mi\n",
    "    quantiles = args.quantiles\n",
    "    sample_weight = args.sample_weight\n",
    "    group = args.group\n",
    "    cv_fold_files = args.cv_fold_files\n",
    "    cv_folds = args.cv_folds\n",
    "    cv_lno = args.cv_lno\n",
    "    n_jobs = args.n_jobs\n",
    "\n",
    "    if calibrate is None:\n",
    "        calibrate = False\n",
    "    else:\n",
    "        calibrate = bool(calibrate)\n",
    "        print(calibrate)\n",
    "\n",
    "    if n_jobs is not None:\n",
    "        n_jobs = int(n_jobs)\n",
    "\n",
    "    # load filenames and labels\n",
    "    sample_images = util.load_sample_images( out_dir )\n",
    "    samples,cats,labels = util.load_labels( out_dir )\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        # get labels for sample_weight category\n",
    "        c = np.where(cats==sample_weight)[0][0]\n",
    "        ln = np.unique([l[c] for l in labels])\n",
    "        ln.sort()\n",
    "        ln = list(ln)\n",
    "        if '' in ln:\n",
    "            del ln[ln.index('')]\n",
    "        label_names_sw = ln\n",
    "        labels_sw = np.array([ ln.index(l) if l in ln else -1 for l in labels[:,c] ])\n",
    "    if group is not None:\n",
    "        # get labels for group category\n",
    "        if group == sample_weight:\n",
    "            label_names_group = label_names_sw\n",
    "            labels_group = labels_sw\n",
    "        else:\n",
    "            c = np.where(cats==group)[0][0]\n",
    "            ln = np.unique([l[c] for l in labels])\n",
    "            ln.sort()\n",
    "            ln = list(ln)\n",
    "            if '' in ln:\n",
    "                del ln[ln.index('')]\n",
    "            label_names_group = ln\n",
    "            labels_group = np.array([ ln.index(l) if l in ln else -1 for l in labels[:,c] ])\n",
    "    if categories is None:\n",
    "        # get labels for list of categories\n",
    "        label_names = []\n",
    "        new_labels = np.zeros(labels.shape,dtype='int')\n",
    "        for c,cat in enumerate(cats):\n",
    "            ln = np.unique([l[c] for l in labels])\n",
    "            ln.sort()\n",
    "            ln = list(ln)\n",
    "            label_names.append( ln )\n",
    "            new_labels[:,c] = [ ln.index(l) for l in labels[:,c] ]\n",
    "        labels = new_labels\n",
    "    else:\n",
    "        # get labels for all categories\n",
    "        label_names = []\n",
    "        categories = categories.split(',')\n",
    "        new_labels = np.zeros((labels.shape[0],len(categories)),dtype='int')\n",
    "        for i,cat in enumerate(categories):\n",
    "            c = np.where(cats==cat)[0][0]\n",
    "            ln = np.unique([l[c] for l in labels])\n",
    "            ln.sort()\n",
    "            ln = list(ln)\n",
    "            if '' in ln:\n",
    "                del ln[ln.index('')]\n",
    "            label_names.append( ln )\n",
    "            new_labels[:,i] = np.array([ ln.index(l) if l in ln else -1 for l in labels[:,c] ])\n",
    "        labels = new_labels\n",
    "        cats = categories\n",
    "        \n",
    "    # read in CNN features\n",
    "    feats = {}\n",
    "    for sample,imagelist in sample_images.items():\n",
    "        feats[sample] = []\n",
    "        for fn in imagelist:\n",
    "            feat_fn = out_dir+fn[:fn.rfind('.')]+'_'+model_name+'-'+layer\n",
    "            if pool_size is not None:\n",
    "                feat_fn += '_p'+str(pool_size)\n",
    "            if instance_size is not None:\n",
    "                feat_fn += '_i'+str(instance_size)\n",
    "            if instance_stride is not None:\n",
    "                feat_fn += '-'+str(instance_stride)\n",
    "            feat_fn += '.npy'\n",
    "            feat = np.load(feat_fn)\n",
    "            if len(feat) == 0:\n",
    "                continue\n",
    "            feats[sample].append( feat )\n",
    "\n",
    "        print('%s %d'%(sample,len(feats[sample])))\n",
    "        feats[sample] = np.concatenate(feats[sample],axis=0)\n",
    "        if len(feats[sample].shape) == 1:\n",
    "            feats[sample] = feats[sample].reshape((1,len(feats[sample])))\n",
    "            \n",
    "        # compute mean if needed\n",
    "        if mi_type is None or mi_type.lower() == 'none':\n",
    "            if len(feats[sample].shape) > 1:\n",
    "                feats[sample] = feats[sample].mean(axis=0)\n",
    "\n",
    "    # build train/test sets\n",
    "    if cv_fold_files is not None:\n",
    "        idx_train_test = util.load_cv_files( out_dir, samples, cv_fold_files )\n",
    "    elif cv_folds is not None or cv_lno is not None:\n",
    "        if cv_folds is not None:\n",
    "            cv_folds = int(cv_folds)\n",
    "        else:\n",
    "            cv_lno = int(cv_lno)\n",
    "            if cv_folds is None:\n",
    "                cv_folds = len(samples) // cv_lno\n",
    "        idx = np.arange(len(samples))\n",
    "        if len(label_names) == 1:\n",
    "            if cv_lno == 1:\n",
    "                skf = sklearn.model_selection.LeaveOneOut()\n",
    "            else:\n",
    "                skf = sklearn.model_selection.StratifiedKFold( n_splits=cv_folds, shuffle=True )\n",
    "            idx_train_test = list(skf.split(idx,labels[:,0]))\n",
    "        else:\n",
    "            # merge label categories to do stratified folds\n",
    "            skf = sklearn.model_selection.StratifiedKFold( n_splits=cv_folds, shuffle=True )\n",
    "            la_all = np.array(labels[:,0])\n",
    "            p = 1\n",
    "            for i in range(labels.shape[1]):\n",
    "                la_all += labels[:,i] * p\n",
    "                p *= len(label_names[i])\n",
    "            idx_train_test = list(skf.split(idx,la_all))\n",
    "    else:\n",
    "        print('Error: train/test split not specified')\n",
    "        sys.exit(1)\n",
    "\n",
    "    options = {}\n",
    "    if kernel is not None:\n",
    "        options['kernel'] = kernel\n",
    "    else:\n",
    "        options['kernel'] = 'linear'\n",
    "    if classifier is not None:\n",
    "        options['classifier'] = classifier\n",
    "    if mi_type is not None:\n",
    "        options['predict_type'] = mi_type\n",
    "    if metric is not None:\n",
    "        options['metric'] = metric\n",
    "                        \n",
    "    for c,cat_name in enumerate(cats):\n",
    "        print(cat_name)\n",
    "        res = ResultsReport(label_names[c])\n",
    "        nfolds = len(idx_train_test)\n",
    "        for f,(idx_train,idx_test) in enumerate(idx_train_test):\n",
    "            print('Fold '+str(f+1)+'/'+str(len(idx_train_test)))\n",
    "            idx_train = idx_train[np.where(labels[idx_train,c]!=-1)[0]]\n",
    "            idx_test = idx_test[np.where(labels[idx_test,c]!=-1)[0]]\n",
    "            X_train = [ feats[samples[i]] for i in idx_train ]\n",
    "            y_train = labels[idx_train,c]\n",
    "            X_test = [ feats[samples[i]] for i in idx_test ]\n",
    "            y_test = labels[idx_test,c]\n",
    "\n",
    "            if sample_weight is not None:\n",
    "                # figure out sample weights\n",
    "                print('Weighting by '+sample_weight)\n",
    "                # discard samples missing a label for sample_weight category\n",
    "                idx_train = idx_train[np.where(labels_sw[idx_train]!=-1)[0]]\n",
    "                X_train = [ feats[samples[i]] for i in idx_train ]\n",
    "                \n",
    "                y_train = labels[idx_train,c]\n",
    "                y_sw = y_train + len(label_names[c])*labels_sw[idx_train]\n",
    "\n",
    "                uniq = np.unique(y_sw).tolist()\n",
    "                counts = np.array([ (y_sw==l).sum() for l in uniq ])\n",
    "                counts = counts.sum().astype(float) / ( counts * len(counts) )\n",
    "                sw = np.array([ counts[uniq.index(y)] for y in y_sw ])\n",
    "            else:\n",
    "                sw = None\n",
    "\n",
    "            if mi_type is None:\n",
    "                model = LinearClassifier( n_jobs=n_jobs, **options )\n",
    "                model.fit( X_train, y_train, calibrate=calibrate, param_search=True, sample_weight=sw )\n",
    "            elif mi_type in ['median','max']:\n",
    "                model = SIL( n_jobs=n_jobs, **options )\n",
    "                model.fit( X_train, y_train, calibrate=calibrate, param_search=True, sample_weight=sw )\n",
    "            elif mi_type == 'quantile':\n",
    "                if quantiles is not None:\n",
    "                    options['quantiles'] = int(quantiles)\n",
    "                model = SIL( n_jobs=n_jobs, **options )\n",
    "                model.fit( X_train, y_train, calibrate=calibrate, param_search=True, sample_weight=sw )\n",
    "                \n",
    "            p_predict = model.predict( X_test )\n",
    "            y_predict = np.argmax(p_predict,axis=1)\n",
    "            acc = sklearn.metrics.accuracy_score( y_test, y_predict )\n",
    "            if len(y_test) == 1:\n",
    "                auc = 0.0\n",
    "            elif len(np.unique(y_train)) == 2:\n",
    "                auc = sklearn.metrics.roc_auc_score( y_test, p_predict[:,1] )\n",
    "            else:\n",
    "                auc = 0.0\n",
    "                for i in range(p_predict.shape[1]):\n",
    "                    auc += sklearn.metrics.roc_auc_score( y_test==i, p_predict[:,i] )\n",
    "                auc /= p_predict.shape[1]\n",
    "            kappa = sklearn.metrics.cohen_kappa_score( y_test, y_predict )\n",
    "            classes = np.unique(y_train)\n",
    "            np.sort(classes)\n",
    "            confusion = sklearn.metrics.confusion_matrix( y_test, y_predict, labels=classes )\n",
    "            res.add('acc',acc)\n",
    "            res.add('auc',auc)\n",
    "            res.add('kappa',kappa)\n",
    "            if len(label_names[c]) == 2:\n",
    "                res.add('sensitivity', float( np.logical_and(y_test==1, y_predict==y_test).sum() ) / (y_test==1).sum() )\n",
    "                res.add('specificity', float( np.logical_and(y_test!=1, y_predict==y_test).sum() ) / (y_test!=1).sum() )\n",
    "            res.add('confusion',confusion)\n",
    "\n",
    "            print('accuracy %f auc %f' % (acc,auc))\n",
    "            print(confusion)\n",
    "\n",
    "            if group is not None:\n",
    "                # within group class metrics\n",
    "                l_group = labels_group[idx_test]\n",
    "                uniq = np.unique(l_group)\n",
    "                uniq.sort()\n",
    "                for u in uniq:\n",
    "                    if u == -1:\n",
    "                        continue\n",
    "                    idx = (l_group==u)\n",
    "\n",
    "                    group_name = '(%s=%s)'%(group,label_names_group[u])\n",
    "                    res.add('accuracy '+group_name,sklearn.metrics.accuracy_score( y_test[idx], y_predict[idx] ))\n",
    "                    if len(np.unique(y_train)) == 2:\n",
    "                        if (y_test[idx]==0).sum() == 0 or (y_test[idx]==1).sum() == 0:\n",
    "                            auc = 0\n",
    "                        else:\n",
    "                            auc = sklearn.metrics.roc_auc_score( y_test[idx], p_predict[idx,1] )\n",
    "                    else:\n",
    "                        auc = 0.0\n",
    "                        for i in range(p_predict.shape[1]):\n",
    "                            auc += sklearn.metrics.roc_auc_score( y_test[idx]==i, p_predict[idx,i] )\n",
    "                        auc /= p_predict.shape[1]\n",
    "                    res.add('auc '+group_name,auc)\n",
    "                    res.add('kappa '+group_name,sklearn.metrics.cohen_kappa_score( y_test[idx], y_predict[idx] ) )\n",
    "                    if len(label_names[c]) == 2:\n",
    "                        res.add('sensitivity '+group_name,float( np.logical_and(y_test[idx]==1, y_predict[idx]==y_test[idx]).sum() ) / (y_test[idx]==1).sum() )\n",
    "                        res.add('specificity '+group_name,float( np.logical_and(y_test[idx]!=1, y_predict[idx]==y_test[idx]).sum() ) / (y_test[idx]!=1).sum() )\n",
    "            \n",
    "        print('Cross-validation results')\n",
    "        res.print_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser( description='Compute CNN features.' )\n",
    "    parser.add_argument('--out_dir', '-o', required=True, help='output directory' )\n",
    "    parser.add_argument('--model', '-m', required=True, help='CNN model' )\n",
    "    parser.add_argument('--layer', '-l', required=True, help='CNN layer' )\n",
    "    parser.add_argument('--instance-size', help='instance size' )\n",
    "    parser.add_argument('--instance-stride', help='instance stride' )\n",
    "    parser.add_argument('--pool-size', '-p', help='mean pooling size' )\n",
    "    parser.add_argument('--cat', help='label categories to train (comma separated); default: all' )\n",
    "    parser.add_argument('--calibrate', action='store_true', help='calibrate classifier' )\n",
    "    parser.add_argument('--metric', help='metric to optimize during parameter search (accuracy, balanced_accuracy, roc_auc); default: accuracy' )\n",
    "    parser.add_argument('--classifier', '-c', help='classifier (svm or logistic); default: all' )\n",
    "    parser.add_argument('--kernel', help='SVM kernel; default: linear' )\n",
    "    parser.add_argument('--mi', help='MI type (none, median, quantile); default: none (compute mean across images)' )\n",
    "    parser.add_argument('--quantiles', '-q', help='Number of quantiles; default: 16' )\n",
    "    parser.add_argument('--sample-weight', help='Weight samples by classification category and this one' )\n",
    "    parser.add_argument('--group', help='Class groups for reporting results' )\n",
    "    parser.add_argument('--cv-fold-files', help='cross-validation fold files' )\n",
    "    parser.add_argument('--cv-folds', help='cross-validation folds' )\n",
    "    parser.add_argument('--cv-lno', help='cross-validation leave n out' )\n",
    "    parser.add_argument('--n-jobs', help='number of parallel threads' )\n",
    "    args = parser.parse_args()\n",
    "    out_dir = args.out_dir\n",
    "    if len(out_dir) > 1 and out_dir[-1] != '/':\n",
    "        out_dir += '/'\n",
    "    model_name = args.model\n",
    "    layer = args.layer\n",
    "    instance_size = args.instance_size\n",
    "    instance_stride = args.instance_stride\n",
    "    pool_size = args.pool_size\n",
    "    categories = args.cat\n",
    "    metric = args.metric\n",
    "    calibrate = args.calibrate\n",
    "    classifier = args.classifier\n",
    "    kernel = args.kernel\n",
    "    mi_type = args.mi\n",
    "    quantiles = args.quantiles\n",
    "    sample_weight = args.sample_weight\n",
    "    group = args.group\n",
    "    cv_fold_files = args.cv_fold_files\n",
    "    cv_folds = args.cv_folds\n",
    "    cv_lno = args.cv_lno\n",
    "    n_jobs = args.n_jobs\n",
    "\n",
    "    if calibrate is None:\n",
    "        calibrate = False\n",
    "    else:\n",
    "        calibrate = bool(calibrate)\n",
    "        print(calibrate)\n",
    "\n",
    "    if n_jobs is not None:\n",
    "        n_jobs = int(n_jobs)\n",
    "\n",
    "    # load filenames and labels\n",
    "    sample_images = util.load_sample_images( out_dir )\n",
    "    samples,cats,labels = util.load_labels( out_dir )\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        # get labels for sample_weight category\n",
    "        c = np.where(cats==sample_weight)[0][0]\n",
    "        ln = np.unique([l[c] for l in labels])\n",
    "        ln.sort()\n",
    "        ln = list(ln)\n",
    "        if '' in ln:\n",
    "            del ln[ln.index('')]\n",
    "        label_names_sw = ln\n",
    "        labels_sw = np.array([ ln.index(l) if l in ln else -1 for l in labels[:,c] ])\n",
    "    if group is not None:\n",
    "        # get labels for group category\n",
    "        if group == sample_weight:\n",
    "            label_names_group = label_names_sw\n",
    "            labels_group = labels_sw\n",
    "        else:\n",
    "            c = np.where(cats==group)[0][0]\n",
    "            ln = np.unique([l[c] for l in labels])\n",
    "            ln.sort()\n",
    "            ln = list(ln)\n",
    "            if '' in ln:\n",
    "                del ln[ln.index('')]\n",
    "            label_names_group = ln\n",
    "            labels_group = np.array([ ln.index(l) if l in ln else -1 for l in labels[:,c] ])\n",
    "    if categories is None:\n",
    "        # get labels for list of categories\n",
    "        label_names = []\n",
    "        new_labels = np.zeros(labels.shape,dtype='int')\n",
    "        for c,cat in enumerate(cats):\n",
    "            ln = np.unique([l[c] for l in labels])\n",
    "            ln.sort()\n",
    "            ln = list(ln)\n",
    "            label_names.append( ln )\n",
    "            new_labels[:,c] = [ ln.index(l) for l in labels[:,c] ]\n",
    "        labels = new_labels\n",
    "    else:\n",
    "        # get labels for all categories\n",
    "        label_names = []\n",
    "        categories = categories.split(',')\n",
    "        new_labels = np.zeros((labels.shape[0],len(categories)),dtype='int')\n",
    "        for i,cat in enumerate(categories):\n",
    "            c = np.where(cats==cat)[0][0]\n",
    "            ln = np.unique([l[c] for l in labels])\n",
    "            ln.sort()\n",
    "            ln = list(ln)\n",
    "            if '' in ln:\n",
    "                del ln[ln.index('')]\n",
    "            label_names.append( ln )\n",
    "            new_labels[:,i] = np.array([ ln.index(l) if l in ln else -1 for l in labels[:,c] ])\n",
    "        labels = new_labels\n",
    "        cats = categories\n",
    "        \n",
    "    # read in CNN features\n",
    "    feats = {}\n",
    "    for sample,imagelist in sample_images.items():\n",
    "        feats[sample] = []\n",
    "        for fn in imagelist:\n",
    "            feat_fn = out_dir+fn[:fn.rfind('.')]+'_'+model_name+'-'+layer\n",
    "            if pool_size is not None:\n",
    "                feat_fn += '_p'+str(pool_size)\n",
    "            if instance_size is not None:\n",
    "                feat_fn += '_i'+str(instance_size)\n",
    "            if instance_stride is not None:\n",
    "                feat_fn += '-'+str(instance_stride)\n",
    "            feat_fn += '.npy'\n",
    "            feat = np.load(feat_fn)\n",
    "            if len(feat) == 0:\n",
    "                continue\n",
    "            feats[sample].append( feat )\n",
    "\n",
    "        print('%s %d'%(sample,len(feats[sample])))\n",
    "        feats[sample] = np.concatenate(feats[sample],axis=0)\n",
    "        if len(feats[sample].shape) == 1:\n",
    "            feats[sample] = feats[sample].reshape((1,len(feats[sample])))\n",
    "            \n",
    "        # compute mean if needed\n",
    "        if mi_type is None or mi_type.lower() == 'none':\n",
    "            if len(feats[sample].shape) > 1:\n",
    "                feats[sample] = feats[sample].mean(axis=0)\n",
    "\n",
    "    # build train/test sets\n",
    "    if cv_fold_files is not None:\n",
    "        idx_train_test = util.load_cv_files( out_dir, samples, cv_fold_files )\n",
    "    elif cv_folds is not None or cv_lno is not None:\n",
    "        if cv_folds is not None:\n",
    "            cv_folds = int(cv_folds)\n",
    "        else:\n",
    "            cv_lno = int(cv_lno)\n",
    "            if cv_folds is None:\n",
    "                cv_folds = len(samples) // cv_lno\n",
    "        idx = np.arange(len(samples))\n",
    "        if len(label_names) == 1:\n",
    "            if cv_lno == 1:\n",
    "                skf = sklearn.model_selection.LeaveOneOut()\n",
    "            else:\n",
    "                skf = sklearn.model_selection.StratifiedKFold( n_splits=cv_folds, shuffle=True )\n",
    "            idx_train_test = list(skf.split(idx,labels[:,0]))\n",
    "        else:\n",
    "            # merge label categories to do stratified folds\n",
    "            skf = sklearn.model_selection.StratifiedKFold( n_splits=cv_folds, shuffle=True )\n",
    "            la_all = np.array(labels[:,0])\n",
    "            p = 1\n",
    "            for i in range(labels.shape[1]):\n",
    "                la_all += labels[:,i] * p\n",
    "                p *= len(label_names[i])\n",
    "            idx_train_test = list(skf.split(idx,la_all))\n",
    "    else:\n",
    "        print('Error: train/test split not specified')\n",
    "        sys.exit(1)\n",
    "\n",
    "    options = {}\n",
    "    if kernel is not None:\n",
    "        options['kernel'] = kernel\n",
    "    else:\n",
    "        options['kernel'] = 'linear'\n",
    "    if classifier is not None:\n",
    "        options['classifier'] = classifier\n",
    "    if mi_type is not None:\n",
    "        options['predict_type'] = mi_type\n",
    "    if metric is not None:\n",
    "        options['metric'] = metric\n",
    "                        \n",
    "    for c,cat_name in enumerate(cats):\n",
    "        print(cat_name)\n",
    "        res = ResultsReport(label_names[c])\n",
    "        nfolds = len(idx_train_test)\n",
    "        for f,(idx_train,idx_test) in enumerate(idx_train_test):\n",
    "            print('Fold '+str(f+1)+'/'+str(len(idx_train_test)))\n",
    "            idx_train = idx_train[np.where(labels[idx_train,c]!=-1)[0]]\n",
    "            idx_test = idx_test[np.where(labels[idx_test,c]!=-1)[0]]\n",
    "            X_train = [ feats[samples[i]] for i in idx_train ]\n",
    "            y_train = labels[idx_train,c]\n",
    "            X_test = [ feats[samples[i]] for i in idx_test ]\n",
    "            y_test = labels[idx_test,c]\n",
    "\n",
    "            if sample_weight is not None:\n",
    "                # figure out sample weights\n",
    "                print('Weighting by '+sample_weight)\n",
    "                # discard samples missing a label for sample_weight category\n",
    "                idx_train = idx_train[np.where(labels_sw[idx_train]!=-1)[0]]\n",
    "                X_train = [ feats[samples[i]] for i in idx_train ]\n",
    "                \n",
    "                y_train = labels[idx_train,c]\n",
    "                y_sw = y_train + len(label_names[c])*labels_sw[idx_train]\n",
    "\n",
    "                uniq = np.unique(y_sw).tolist()\n",
    "                counts = np.array([ (y_sw==l).sum() for l in uniq ])\n",
    "                counts = counts.sum().astype(float) / ( counts * len(counts) )\n",
    "                sw = np.array([ counts[uniq.index(y)] for y in y_sw ])\n",
    "            else:\n",
    "                sw = None\n",
    "\n",
    "            if mi_type is None:\n",
    "                model = LinearClassifier( n_jobs=n_jobs, **options )\n",
    "                model.fit( X_train, y_train, calibrate=calibrate, param_search=True, sample_weight=sw )\n",
    "            elif mi_type in ['median','max']:\n",
    "                model = SIL( n_jobs=n_jobs, **options )\n",
    "                model.fit( X_train, y_train, calibrate=calibrate, param_search=True, sample_weight=sw )\n",
    "            elif mi_type == 'quantile':\n",
    "                if quantiles is not None:\n",
    "                    options['quantiles'] = int(quantiles)\n",
    "                model = SIL( n_jobs=n_jobs, **options )\n",
    "                model.fit( X_train, y_train, calibrate=calibrate, param_search=True, sample_weight=sw )\n",
    "                \n",
    "            p_predict = model.predict( X_test )\n",
    "            y_predict = np.argmax(p_predict,axis=1)\n",
    "            acc = sklearn.metrics.accuracy_score( y_test, y_predict )\n",
    "            if len(y_test) == 1:\n",
    "                auc = 0.0\n",
    "            elif len(np.unique(y_train)) == 2:\n",
    "                auc = sklearn.metrics.roc_auc_score( y_test, p_predict[:,1] )\n",
    "            else:\n",
    "                auc = 0.0\n",
    "                for i in range(p_predict.shape[1]):\n",
    "                    auc += sklearn.metrics.roc_auc_score( y_test==i, p_predict[:,i] )\n",
    "                auc /= p_predict.shape[1]\n",
    "            kappa = sklearn.metrics.cohen_kappa_score( y_test, y_predict )\n",
    "            classes = np.unique(y_train)\n",
    "            np.sort(classes)\n",
    "            confusion = sklearn.metrics.confusion_matrix( y_test, y_predict, labels=classes )\n",
    "            res.add('acc',acc)\n",
    "            res.add('auc',auc)\n",
    "            res.add('kappa',kappa)\n",
    "            if len(label_names[c]) == 2:\n",
    "                res.add('sensitivity', float( np.logical_and(y_test==1, y_predict==y_test).sum() ) / (y_test==1).sum() )\n",
    "                res.add('specificity', float( np.logical_and(y_test!=1, y_predict==y_test).sum() ) / (y_test!=1).sum() )\n",
    "            res.add('confusion',confusion)\n",
    "\n",
    "            print('accuracy %f auc %f' % (acc,auc))\n",
    "            print(confusion)\n",
    "\n",
    "            if group is not None:\n",
    "                # within group class metrics\n",
    "                l_group = labels_group[idx_test]\n",
    "                uniq = np.unique(l_group)\n",
    "                uniq.sort()\n",
    "                for u in uniq:\n",
    "                    if u == -1:\n",
    "                        continue\n",
    "                    idx = (l_group==u)\n",
    "\n",
    "                    group_name = '(%s=%s)'%(group,label_names_group[u])\n",
    "                    res.add('accuracy '+group_name,sklearn.metrics.accuracy_score( y_test[idx], y_predict[idx] ))\n",
    "                    if len(np.unique(y_train)) == 2:\n",
    "                        if (y_test[idx]==0).sum() == 0 or (y_test[idx]==1).sum() == 0:\n",
    "                            auc = 0\n",
    "                        else:\n",
    "                            auc = sklearn.metrics.roc_auc_score( y_test[idx], p_predict[idx,1] )\n",
    "                    else:\n",
    "                        auc = 0.0\n",
    "                        for i in range(p_predict.shape[1]):\n",
    "                            auc += sklearn.metrics.roc_auc_score( y_test[idx]==i, p_predict[idx,i] )\n",
    "                        auc /= p_predict.shape[1]\n",
    "                    res.add('auc '+group_name,auc)\n",
    "                    res.add('kappa '+group_name,sklearn.metrics.cohen_kappa_score( y_test[idx], y_predict[idx] ) )\n",
    "                    if len(label_names[c]) == 2:\n",
    "                        res.add('sensitivity '+group_name,float( np.logical_and(y_test[idx]==1, y_predict[idx]==y_test[idx]).sum() ) / (y_test[idx]==1).sum() )\n",
    "                        res.add('specificity '+group_name,float( np.logical_and(y_test[idx]!=1, y_predict[idx]==y_test[idx]).sum() ) / (y_test[idx]!=1).sum() )\n",
    "            \n",
    "        print('Cross-validation results')\n",
    "        res.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser( description='Compute CNN features.' )\n",
    "    parser.add_argument('--out_dir', '-o', required=True, help='output directory' )\n",
    "    parser.add_argument('--model', '-m', required=True, help='CNN model' )\n",
    "    parser.add_argument('--layer', '-l', required=True, help='CNN layer' )\n",
    "    parser.add_argument('--instance-size', help='instance size' )\n",
    "    parser.add_argument('--instance-stride', help='instance stride' )\n",
    "    parser.add_argument('--pool-size', '-p', help='mean pooling size' )\n",
    "    parser.add_argument('--cat', help='label categories to train (comma separated); default: all' )\n",
    "    parser.add_argument('--calibrate', action='store_true', help='calibrate classifier' )\n",
    "    parser.add_argument('--metric', help='metric to optimize during parameter search (accuracy, balanced_accuracy, roc_auc); default: accuracy' )\n",
    "    parser.add_argument('--classifier', '-c', help='classifier (svm or logistic); default: all' )\n",
    "    parser.add_argument('--kernel', help='SVM kernel; default: linear' )\n",
    "    parser.add_argument('--mi', help='MI type (none, median, quantile); default: none (compute mean across images)' )\n",
    "    parser.add_argument('--quantiles', '-q', help='Number of quantiles; default: 16' )\n",
    "    parser.add_argument('--sample-weight', help='Weight samples by classification category and this one' )\n",
    "    parser.add_argument('--group', help='Class groups for reporting results' )\n",
    "    parser.add_argument('--cv-fold-files', help='cross-validation fold files' )\n",
    "    parser.add_argument('--cv-folds', help='cross-validation folds' )\n",
    "    parser.add_argument('--cv-lno', help='cross-validation leave n out' )\n",
    "    parser.add_argument('--n-jobs', help='number of parallel threads' )\n",
    "    args = parser.parse_args()\n",
    "    out_dir = args.out_dir\n",
    "    if len(out_dir) > 1 and out_dir[-1] != '/':\n",
    "        out_dir += '/'\n",
    "    model_name = args.model\n",
    "    layer = args.layer\n",
    "    instance_size = args.instance_size\n",
    "    instance_stride = args.instance_stride\n",
    "    pool_size = args.pool_size\n",
    "    categories = args.cat\n",
    "    metric = args.metric\n",
    "    calibrate = args.calibrate\n",
    "    classifier = args.classifier\n",
    "    kernel = args.kernel\n",
    "    mi_type = args.mi\n",
    "    quantiles = args.quantiles\n",
    "    sample_weight = args.sample_weight\n",
    "    group = args.group\n",
    "    cv_fold_files = args.cv_fold_files\n",
    "    cv_folds = args.cv_folds\n",
    "    cv_lno = args.cv_lno\n",
    "    n_jobs = args.n_jobs\n",
    "\n",
    "    if calibrate is None:\n",
    "        calibrate = False\n",
    "    else:\n",
    "        calibrate = bool(calibrate)\n",
    "        print(calibrate)\n",
    "\n",
    "    if n_jobs is not None:\n",
    "        n_jobs = int(n_jobs)\n",
    "\n",
    "    # load filenames and labels\n",
    "    sample_images = util.load_sample_images( out_dir )\n",
    "    samples,cats,labels = util.load_labels( out_dir )\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        # get labels for sample_weight category\n",
    "        c = np.where(cats==sample_weight)[0][0]\n",
    "        ln = np.unique([l[c] for l in labels])\n",
    "        ln.sort()\n",
    "        ln = list(ln)\n",
    "        if '' in ln:\n",
    "            del ln[ln.index('')]\n",
    "        label_names_sw = ln\n",
    "        labels_sw = np.array([ ln.index(l) if l in ln else -1 for l in labels[:,c] ])\n",
    "    if group is not None:\n",
    "        # get labels for group category\n",
    "        if group == sample_weight:\n",
    "            label_names_group = label_names_sw\n",
    "            labels_group = labels_sw\n",
    "        else:\n",
    "            c = np.where(cats==group)[0][0]\n",
    "            ln = np.unique([l[c] for l in labels])\n",
    "            ln.sort()\n",
    "            ln = list(ln)\n",
    "            if '' in ln:\n",
    "                del ln[ln.index('')]\n",
    "            label_names_group = ln\n",
    "            labels_group = np.array([ ln.index(l) if l in ln else -1 for l in labels[:,c] ])\n",
    "    if categories is None:\n",
    "        # get labels for list of categories\n",
    "        label_names = []\n",
    "        new_labels = np.zeros(labels.shape,dtype='int')\n",
    "        for c,cat in enumerate(cats):\n",
    "            ln = np.unique([l[c] for l in labels])\n",
    "            ln.sort()\n",
    "            ln = list(ln)\n",
    "            label_names.append( ln )\n",
    "            new_labels[:,c] = [ ln.index(l) for l in labels[:,c] ]\n",
    "        labels = new_labels\n",
    "    else:\n",
    "        # get labels for all categories\n",
    "        label_names = []\n",
    "        categories = categories.split(',')\n",
    "        new_labels = np.zeros((labels.shape[0],len(categories)),dtype='int')\n",
    "        for i,cat in enumerate(categories):\n",
    "            c = np.where(cats==cat)[0][0]\n",
    "            ln = np.unique([l[c] for l in labels])\n",
    "            ln.sort()\n",
    "            ln = list(ln)\n",
    "            if '' in ln:\n",
    "                del ln[ln.index('')]\n",
    "            label_names.append( ln )\n",
    "            new_labels[:,i] = np.array([ ln.index(l) if l in ln else -1 for l in labels[:,c] ])\n",
    "        labels = new_labels\n",
    "        cats = categories\n",
    "        \n",
    "    # read in CNN features\n",
    "    feats = {}\n",
    "    for sample,imagelist in sample_images.items():\n",
    "        feats[sample] = []\n",
    "        for fn in imagelist:\n",
    "            feat_fn = out_dir+fn[:fn.rfind('.')]+'_'+model_name+'-'+layer\n",
    "            if pool_size is not None:\n",
    "                feat_fn += '_p'+str(pool_size)\n",
    "            if instance_size is not None:\n",
    "                feat_fn += '_i'+str(instance_size)\n",
    "            if instance_stride is not None:\n",
    "                feat_fn += '-'+str(instance_stride)\n",
    "            feat_fn += '.npy'\n",
    "            feat = np.load(feat_fn)\n",
    "            if len(feat) == 0:\n",
    "                continue\n",
    "            feats[sample].append( feat )\n",
    "\n",
    "        print('%s %d'%(sample,len(feats[sample])))\n",
    "        feats[sample] = np.concatenate(feats[sample],axis=0)\n",
    "        if len(feats[sample].shape) == 1:\n",
    "            feats[sample] = feats[sample].reshape((1,len(feats[sample])))\n",
    "            \n",
    "        # compute mean if needed\n",
    "        if mi_type is None or mi_type.lower() == 'none':\n",
    "            if len(feats[sample].shape) > 1:\n",
    "                feats[sample] = feats[sample].mean(axis=0)\n",
    "\n",
    "    # build train/test sets\n",
    "    if cv_fold_files is not None:\n",
    "        idx_train_test = util.load_cv_files( out_dir, samples, cv_fold_files )\n",
    "    elif cv_folds is not None or cv_lno is not None:\n",
    "        if cv_folds is not None:\n",
    "            cv_folds = int(cv_folds)\n",
    "        else:\n",
    "            cv_lno = int(cv_lno)\n",
    "            if cv_folds is None:\n",
    "                cv_folds = len(samples) // cv_lno\n",
    "        idx = np.arange(len(samples))\n",
    "        if len(label_names) == 1:\n",
    "            if cv_lno == 1:\n",
    "                skf = sklearn.model_selection.LeaveOneOut()\n",
    "            else:\n",
    "                skf = sklearn.model_selection.StratifiedKFold( n_splits=cv_folds, shuffle=True )\n",
    "            idx_train_test = list(skf.split(idx,labels[:,0]))\n",
    "        else:\n",
    "            # merge label categories to do stratified folds\n",
    "            skf = sklearn.model_selection.StratifiedKFold( n_splits=cv_folds, shuffle=True )\n",
    "            la_all = np.array(labels[:,0])\n",
    "            p = 1\n",
    "            for i in range(labels.shape[1]):\n",
    "                la_all += labels[:,i] * p\n",
    "                p *= len(label_names[i])\n",
    "            idx_train_test = list(skf.split(idx,la_all))\n",
    "    else:\n",
    "        print('Error: train/test split not specified')\n",
    "        sys.exit(1)\n",
    "\n",
    "    options = {}\n",
    "    if kernel is not None:\n",
    "        options['kernel'] = kernel\n",
    "    else:\n",
    "        options['kernel'] = 'linear'\n",
    "    if classifier is not None:\n",
    "        options['classifier'] = classifier\n",
    "    if mi_type is not None:\n",
    "        options['predict_type'] = mi_type\n",
    "    if metric is not None:\n",
    "        options['metric'] = metric\n",
    "                        \n",
    "    for c,cat_name in enumerate(cats):\n",
    "        print(cat_name)\n",
    "        res = ResultsReport(label_names[c])\n",
    "        nfolds = len(idx_train_test)\n",
    "        for f,(idx_train,idx_test) in enumerate(idx_train_test):\n",
    "            print('Fold '+str(f+1)+'/'+str(len(idx_train_test)))\n",
    "            idx_train = idx_train[np.where(labels[idx_train,c]!=-1)[0]]\n",
    "            idx_test = idx_test[np.where(labels[idx_test,c]!=-1)[0]]\n",
    "            X_train = [ feats[samples[i]] for i in idx_train ]\n",
    "            y_train = labels[idx_train,c]\n",
    "            X_test = [ feats[samples[i]] for i in idx_test ]\n",
    "            y_test = labels[idx_test,c]\n",
    "\n",
    "            if sample_weight is not None:\n",
    "                # figure out sample weights\n",
    "                print('Weighting by '+sample_weight)\n",
    "                # discard samples missing a label for sample_weight category\n",
    "                idx_train = idx_train[np.where(labels_sw[idx_train]!=-1)[0]]\n",
    "                X_train = [ feats[samples[i]] for i in idx_train ]\n",
    "                \n",
    "                y_train = labels[idx_train,c]\n",
    "                y_sw = y_train + len(label_names[c])*labels_sw[idx_train]\n",
    "\n",
    "                uniq = np.unique(y_sw).tolist()\n",
    "                counts = np.array([ (y_sw==l).sum() for l in uniq ])\n",
    "                counts = counts.sum().astype(float) / ( counts * len(counts) )\n",
    "                sw = np.array([ counts[uniq.index(y)] for y in y_sw ])\n",
    "            else:\n",
    "                sw = None\n",
    "\n",
    "            if mi_type is None:\n",
    "                model = LinearClassifier( n_jobs=n_jobs, **options )\n",
    "                model.fit( X_train, y_train, calibrate=calibrate, param_search=True, sample_weight=sw )\n",
    "            elif mi_type in ['median','max']:\n",
    "                model = SIL( n_jobs=n_jobs, **options )\n",
    "                model.fit( X_train, y_train, calibrate=calibrate, param_search=True, sample_weight=sw )\n",
    "            elif mi_type == 'quantile':\n",
    "                if quantiles is not None:\n",
    "                    options['quantiles'] = int(quantiles)\n",
    "                model = SIL( n_jobs=n_jobs, **options )\n",
    "                model.fit( X_train, y_train, calibrate=calibrate, param_search=True, sample_weight=sw )\n",
    "                \n",
    "            p_predict = model.predict( X_test )\n",
    "            y_predict = np.argmax(p_predict,axis=1)\n",
    "            acc = sklearn.metrics.accuracy_score( y_test, y_predict )\n",
    "            if len(y_test) == 1:\n",
    "                auc = 0.0\n",
    "            elif len(np.unique(y_train)) == 2:\n",
    "                auc = sklearn.metrics.roc_auc_score( y_test, p_predict[:,1] )\n",
    "            else:\n",
    "                auc = 0.0\n",
    "                for i in range(p_predict.shape[1]):\n",
    "                    auc += sklearn.metrics.roc_auc_score( y_test==i, p_predict[:,i] )\n",
    "                auc /= p_predict.shape[1]\n",
    "            kappa = sklearn.metrics.cohen_kappa_score( y_test, y_predict )\n",
    "            classes = np.unique(y_train)\n",
    "            np.sort(classes)\n",
    "            confusion = sklearn.metrics.confusion_matrix( y_test, y_predict, labels=classes )\n",
    "            res.add('acc',acc)\n",
    "            res.add('auc',auc)\n",
    "            res.add('kappa',kappa)\n",
    "            if len(label_names[c]) == 2:\n",
    "                res.add('sensitivity', float( np.logical_and(y_test==1, y_predict==y_test).sum() ) / (y_test==1).sum() )\n",
    "                res.add('specificity', float( np.logical_and(y_test!=1, y_predict==y_test).sum() ) / (y_test!=1).sum() )\n",
    "            res.add('confusion',confusion)\n",
    "\n",
    "            print('accuracy %f auc %f' % (acc,auc))\n",
    "            print(confusion)\n",
    "\n",
    "            if group is not None:\n",
    "                # within group class metrics\n",
    "                l_group = labels_group[idx_test]\n",
    "                uniq = np.unique(l_group)\n",
    "                uniq.sort()\n",
    "                for u in uniq:\n",
    "                    if u == -1:\n",
    "                        continue\n",
    "                    idx = (l_group==u)\n",
    "\n",
    "                    group_name = '(%s=%s)'%(group,label_names_group[u])\n",
    "                    res.add('accuracy '+group_name,sklearn.metrics.accuracy_score( y_test[idx], y_predict[idx] ))\n",
    "                    if len(np.unique(y_train)) == 2:\n",
    "                        if (y_test[idx]==0).sum() == 0 or (y_test[idx]==1).sum() == 0:\n",
    "                            auc = 0\n",
    "                        else:\n",
    "                            auc = sklearn.metrics.roc_auc_score( y_test[idx], p_predict[idx,1] )\n",
    "                    else:\n",
    "                        auc = 0.0\n",
    "                        for i in range(p_predict.shape[1]):\n",
    "                            auc += sklearn.metrics.roc_auc_score( y_test[idx]==i, p_predict[idx,i] )\n",
    "                        auc /= p_predict.shape[1]\n",
    "                    res.add('auc '+group_name,auc)\n",
    "                    res.add('kappa '+group_name,sklearn.metrics.cohen_kappa_score( y_test[idx], y_predict[idx] ) )\n",
    "                    if len(label_names[c]) == 2:\n",
    "                        res.add('sensitivity '+group_name,float( np.logical_and(y_test[idx]==1, y_predict[idx]==y_test[idx]).sum() ) / (y_test[idx]==1).sum() )\n",
    "                        res.add('specificity '+group_name,float( np.logical_and(y_test[idx]!=1, y_predict[idx]==y_test[idx]).sum() ) / (y_test[idx]!=1).sum() )\n",
    "            \n",
    "        print('Cross-validation results')\n",
    "        res.print_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python run_mi_classify.py -o BreaKHis200/ -m vgg16 -l block4_pool --cat tumor --cv-fold-files fold* --pool-size 5 --mi median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#description='Compute CNN features.'\n",
    "\n",
    "#required parameters\n",
    "out_dir = os.path.join(os.getcwd(), 'BreaKHis200/')  #'-o', required=True, help='output directory'\n",
    "model_name = 'vgg16' #'-m', required=True, help='CNN model'\n",
    "layer = 'block4_pool' #'-l', required=True, help='CNN layer.'\n",
    "\n",
    "#if only 3 parameters are used:\n",
    "#python run_mi_classify.py -o BreaKHis200/ -m vgg16 -l block4_pool_p5\n",
    "\n",
    "#optional parameters \n",
    "pool_size = '5' #'--pool-size', '-p', help='mean pooling size'\n",
    "metric = 'accuracy' #'--metric', help='metric to optimize during parameter search (accuracy, balanced_accuracy, roc_auc); default: accuracy'\n",
    "calibrate = False #'--calibrate', action='store_true', help='calibrate classifier (True or False); default: False'\n",
    "classifier = 'svm' #'--classifier', '-c', help='classifier (svm or logistic); default: all'\n",
    "kernel = 'linear' #'--kernel', help='SVM kernel; default: linear' \n",
    "mi_type = 'median' #'--mi', help='MI type (none, median, quantile); default: none (compute mean across images)' \n",
    "\n",
    "#not defined\n",
    "instance_size = None #'--instance-size', help='instance size' \n",
    "instance_stride = None #'--instance-stride', help='instance stride'\n",
    "cv_fold_files = None #'--cv-fold-files', help='cross-validation fold files; default: None'\n",
    "cv_folds = None #'--cv-folds', help='cross-validation folds; default: None'\n",
    "cv_lno = None #'--cv-lno', help='cross-validation leave n out; default: None'\n",
    "n_jobs = '0' #'--n-jobs', help='number of parallel threads; default: 0'\n",
    "group = None #'--group', help='Class groups for reporting results'\n",
    "quantiles = '16' #'--quantiles', '-q', help='Number of quantiles; default: 16'\n",
    "sample_weight = None #'--sample-weight', help='Weight samples by classification category and this one'\n",
    "categories = None #'--cat', help='label categories to train (comma separated, tumor); default: all, tumor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load filenames and labels\n",
    "sample_images = util.load_sample_images(out_dir)\n",
    "samples,cats,labels = util.load_labels(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "2013\n"
     ]
    }
   ],
   "source": [
    "print(type(sample_images))\n",
    "print(len(sample_images.keys()))\n",
    "#print(sample_images.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(samples))\n",
    "print(type(cats))\n",
    "print(type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate optional features: not worked\n",
    "if sample_weight is not None:\n",
    "    # get labels for sample_weight category\n",
    "    c = np.where(cats==sample_weight)[0][0]\n",
    "    ln = np.unique([l[c] for l in labels])\n",
    "    ln.sort()\n",
    "    ln = list(ln)\n",
    "    if '' in ln:\n",
    "        del ln[ln.index('')]\n",
    "    label_names_sw = ln\n",
    "    labels_sw = np.array([ ln.index(l) if l in ln else -1 for l in labels[:,c] ])\n",
    "    \n",
    "if group is not None:\n",
    "    # get labels for group category\n",
    "    if group == sample_weight:\n",
    "        label_names_group = label_names_sw\n",
    "        labels_group = labels_sw\n",
    "    else:\n",
    "        c = np.where(cats==group)[0][0]\n",
    "        ln = np.unique([l[c] for l in labels])\n",
    "        ln.sort()\n",
    "        ln = list(ln)\n",
    "        if '' in ln:\n",
    "            del ln[ln.index('')]\n",
    "        label_names_group = ln\n",
    "        labels_group = np.array([ ln.index(l) if l in ln else -1 for l in labels[:,c] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#samples,cats,labels = util.load_labels(out_dir)\n",
    "categories = 'tumor'\n",
    "print(type(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tumor\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#works\n",
    "if categories is None:\n",
    "    # get labels for list of categories\n",
    "    label_names = []\n",
    "    new_labels = np.zeros(labels.shape,dtype='int')\n",
    "    #print(new_labels.shape)\n",
    "    \n",
    "    for c,cat in enumerate(cats):\n",
    "        ln = np.unique([l[c] for l in labels])\n",
    "        #print(ln)\n",
    "        ln.sort()\n",
    "        ln = list(ln)\n",
    "        label_names.append(ln)\n",
    "        #print(label_names)\n",
    "        new_labels[:,c] = [ln.index(l) for l in labels[:,c]]\n",
    "        #print(len(new_labels))\n",
    "    labels = new_labels\n",
    "#currently testing this\n",
    "else:\n",
    "    # get labels for all categories\n",
    "    label_names = []\n",
    "    cats = categories.split(',')\n",
    "    print(len(cats))\n",
    "    new_labels = np.zeros((labels.shape[0],len(cats)),dtype='int')\n",
    "    for i,cat in enumerate(cats):\n",
    "        print(cat)\n",
    "        if len(cats) > 1:\n",
    "            c = np.where(cats==cat)[0][0]\n",
    "        else:\n",
    "            c = 0\n",
    "        print(c)\n",
    "        break\n",
    "        ln = np.unique([l[c] for l in labels])\n",
    "        ln.sort()\n",
    "        ln = list(ln)\n",
    "        if '' in ln:\n",
    "            del ln[ln.index('')]\n",
    "        label_names.append( ln )\n",
    "        new_labels[:,i] = np.array([ ln.index(l) if l in ln else -1 for l in labels[:,c] ])\n",
    "    labels = new_labels\n",
    "    cats = categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in CNN features\n",
    "feats = {}\n",
    "for sample,imagelist in sample_images.items():\n",
    "    feats[sample] = []\n",
    "    for fn in imagelist:\n",
    "        feat_fn = out_dir+fn[:fn.rfind('.')]+'_'+model_name+'-'+layer\n",
    "        if pool_size is not None:\n",
    "            feat_fn += '_p'+str(pool_size)\n",
    "        if instance_size is not None:\n",
    "            feat_fn += '_i'+str(instance_size)\n",
    "        if instance_stride is not None:\n",
    "            feat_fn += '-'+str(instance_stride)\n",
    "        feat_fn += '.npy'\n",
    "        feat = np.load(feat_fn)\n",
    "        if len(feat) == 0:\n",
    "            continue\n",
    "        feats[sample].append( feat )\n",
    "\n",
    "    print('%s %d'%(sample,len(feats[sample])))\n",
    "    feats[sample] = np.concatenate(feats[sample],axis=0)\n",
    "    if len(feats[sample].shape) == 1:\n",
    "        feats[sample] = feats[sample].reshape((1,len(feats[sample])))\n",
    "            \n",
    "    # compute mean if needed\n",
    "    if mi_type is None or mi_type.lower() == 'none':\n",
    "        if len(feats[sample].shape) > 1:\n",
    "            feats[sample] = feats[sample].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build train/test sets\n",
    "if cv_fold_files is not None:\n",
    "    idx_train_test = util.load_cv_files( out_dir, samples, cv_fold_files )\n",
    "elif cv_folds is not None or cv_lno is not None:\n",
    "    if cv_folds is not None:\n",
    "        cv_folds = int(cv_folds)\n",
    "    else:\n",
    "        cv_lno = int(cv_lno)\n",
    "        if cv_folds is None:\n",
    "            cv_folds = len(samples) // cv_lno\n",
    "    idx = np.arange(len(samples))\n",
    "    if len(label_names) == 1:\n",
    "        if cv_lno == 1:\n",
    "            skf = sklearn.model_selection.LeaveOneOut()\n",
    "        else:\n",
    "            skf = sklearn.model_selection.StratifiedKFold( n_splits=cv_folds, shuffle=True )\n",
    "        idx_train_test = list(skf.split(idx,labels[:,0]))\n",
    "    else:\n",
    "        # merge label categories to do stratified folds\n",
    "        skf = sklearn.model_selection.StratifiedKFold( n_splits=cv_folds, shuffle=True )\n",
    "        la_all = np.array(labels[:,0])\n",
    "        p = 1\n",
    "        for i in range(labels.shape[1]):\n",
    "            la_all += labels[:,i] * p\n",
    "            p *= len(label_names[i])\n",
    "        idx_train_test = list(skf.split(idx,la_all))\n",
    "else:\n",
    "    print('Error: train/test split not specified')\n",
    "    sys.exit(1)\n",
    "\n",
    "options = {}\n",
    "if kernel is not None:\n",
    "    options['kernel'] = kernel\n",
    "else:\n",
    "    options['kernel'] = 'linear'\n",
    "if classifier is not None:\n",
    "    options['classifier'] = classifier\n",
    "if mi_type is not None:\n",
    "    options['predict_type'] = mi_type\n",
    "if metric is not None:\n",
    "    options['metric'] = metric    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,cat_name in enumerate(cats):\n",
    "        print(cat_name)\n",
    "        res = ResultsReport(label_names[c])\n",
    "        nfolds = len(idx_train_test)\n",
    "        for f,(idx_train,idx_test) in enumerate(idx_train_test):\n",
    "            print('Fold '+str(f+1)+'/'+str(len(idx_train_test)))\n",
    "            idx_train = idx_train[np.where(labels[idx_train,c]!=-1)[0]]\n",
    "            idx_test = idx_test[np.where(labels[idx_test,c]!=-1)[0]]\n",
    "            X_train = [ feats[samples[i]] for i in idx_train ]\n",
    "            y_train = labels[idx_train,c]\n",
    "            X_test = [ feats[samples[i]] for i in idx_test ]\n",
    "            y_test = labels[idx_test,c]\n",
    "\n",
    "            if sample_weight is not None:\n",
    "                # figure out sample weights\n",
    "                print('Weighting by '+sample_weight)\n",
    "                # discard samples missing a label for sample_weight category\n",
    "                idx_train = idx_train[np.where(labels_sw[idx_train]!=-1)[0]]\n",
    "                X_train = [ feats[samples[i]] for i in idx_train ]\n",
    "                \n",
    "                y_train = labels[idx_train,c]\n",
    "                y_sw = y_train + len(label_names[c])*labels_sw[idx_train]\n",
    "\n",
    "                uniq = np.unique(y_sw).tolist()\n",
    "                counts = np.array([ (y_sw==l).sum() for l in uniq ])\n",
    "                counts = counts.sum().astype(float) / ( counts * len(counts) )\n",
    "                sw = np.array([ counts[uniq.index(y)] for y in y_sw ])\n",
    "            else:\n",
    "                sw = None\n",
    "\n",
    "            if mi_type is None:\n",
    "                model = LinearClassifier( n_jobs=n_jobs, **options )\n",
    "                model.fit( X_train, y_train, calibrate=calibrate, param_search=True, sample_weight=sw )\n",
    "            elif mi_type in ['median','max']:\n",
    "                model = SIL( n_jobs=n_jobs, **options )\n",
    "                model.fit( X_train, y_train, calibrate=calibrate, param_search=True, sample_weight=sw )\n",
    "            elif mi_type == 'quantile':\n",
    "                if quantiles is not None:\n",
    "                    options['quantiles'] = int(quantiles)\n",
    "                model = SIL( n_jobs=n_jobs, **options )\n",
    "                model.fit( X_train, y_train, calibrate=calibrate, param_search=True, sample_weight=sw )\n",
    "                \n",
    "            p_predict = model.predict( X_test )\n",
    "            y_predict = np.argmax(p_predict,axis=1)\n",
    "            acc = sklearn.metrics.accuracy_score( y_test, y_predict )\n",
    "            if len(y_test) == 1:\n",
    "                auc = 0.0\n",
    "            elif len(np.unique(y_train)) == 2:\n",
    "                auc = sklearn.metrics.roc_auc_score( y_test, p_predict[:,1] )\n",
    "            else:\n",
    "                auc = 0.0\n",
    "                for i in range(p_predict.shape[1]):\n",
    "                    auc += sklearn.metrics.roc_auc_score( y_test==i, p_predict[:,i] )\n",
    "                auc /= p_predict.shape[1]\n",
    "            kappa = sklearn.metrics.cohen_kappa_score( y_test, y_predict )\n",
    "            classes = np.unique(y_train)\n",
    "            np.sort(classes)\n",
    "            confusion = sklearn.metrics.confusion_matrix( y_test, y_predict, labels=classes )\n",
    "            res.add('acc',acc)\n",
    "            res.add('auc',auc)\n",
    "            res.add('kappa',kappa)\n",
    "            if len(label_names[c]) == 2:\n",
    "                res.add('sensitivity', float( np.logical_and(y_test==1, y_predict==y_test).sum() ) / (y_test==1).sum() )\n",
    "                res.add('specificity', float( np.logical_and(y_test!=1, y_predict==y_test).sum() ) / (y_test!=1).sum() )\n",
    "            res.add('confusion',confusion)\n",
    "\n",
    "            print('accuracy %f auc %f' % (acc,auc))\n",
    "            print(confusion)\n",
    "\n",
    "            if group is not None:\n",
    "                # within group class metrics\n",
    "                l_group = labels_group[idx_test]\n",
    "                uniq = np.unique(l_group)\n",
    "                uniq.sort()\n",
    "                for u in uniq:\n",
    "                    if u == -1:\n",
    "                        continue\n",
    "                    idx = (l_group==u)\n",
    "\n",
    "                    group_name = '(%s=%s)'%(group,label_names_group[u])\n",
    "                    res.add('accuracy '+group_name,sklearn.metrics.accuracy_score( y_test[idx], y_predict[idx] ))\n",
    "                    if len(np.unique(y_train)) == 2:\n",
    "                        if (y_test[idx]==0).sum() == 0 or (y_test[idx]==1).sum() == 0:\n",
    "                            auc = 0\n",
    "                        else:\n",
    "                            auc = sklearn.metrics.roc_auc_score( y_test[idx], p_predict[idx,1] )\n",
    "                    else:\n",
    "                        auc = 0.0\n",
    "                        for i in range(p_predict.shape[1]):\n",
    "                            auc += sklearn.metrics.roc_auc_score( y_test[idx]==i, p_predict[idx,i] )\n",
    "                        auc /= p_predict.shape[1]\n",
    "                    res.add('auc '+group_name,auc)\n",
    "                    res.add('kappa '+group_name,sklearn.metrics.cohen_kappa_score( y_test[idx], y_predict[idx] ) )\n",
    "                    if len(label_names[c]) == 2:\n",
    "                        res.add('sensitivity '+group_name,float( np.logical_and(y_test[idx]==1, y_predict[idx]==y_test[idx]).sum() ) / (y_test[idx]==1).sum() )\n",
    "                        res.add('specificity '+group_name,float( np.logical_and(y_test[idx]!=1, y_predict[idx]==y_test[idx]).sum() ) / (y_test[idx]!=1).sum() )\n",
    "            \n",
    "        print('Cross-validation results')\n",
    "        res.print_summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
